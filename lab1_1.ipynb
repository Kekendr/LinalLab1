{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Bisect:\n",
    "    \"\"\"\n",
    "    Класс, реализующий поиск корней уравнения f(x)=0:\n",
    "    1) Метод бисекции для одного корня (find_one_koran).\n",
    "    2) Сканирование всего интервала, чтобы найти все корни\n",
    "    (find_all_korans).\n",
    "    \"\"\"\n",
    "    def __init__(self, f, epsilon=1e-7, max_iter=100, merge_epsilon=1e-4):\n",
    "        \"\"\"\n",
    "        Инициализация класса\n",
    "        Параметры:\n",
    "        F: callable\n",
    "        Функция: f(x)\n",
    "        Epsilon: float\n",
    "        Точность (для критерия остановки по длине отрезка в\n",
    "        бисекции)\n",
    "        Max_iter: int\n",
    "        Максимальное кол-во итераций в методе бисекции\n",
    "        Merge_epsilon: float\n",
    "        Порог слияния близких корней при поиске всех корней\n",
    "        \"\"\"\n",
    "        self.f = f\n",
    "        self.epsilon = epsilon\n",
    "        self.max_iter = max_iter\n",
    "        self.merge_epsilon = merge_epsilon\n",
    "\n",
    "    def find_one_koran(self, a, b):\n",
    "        \"\"\"\n",
    "        Ищет ОДИН корень f(x)=0 на отрезке [a,b] методом бисекции.\n",
    "        Предполагает, что f(a)*f(b) <= 0, иначе выбрасывает ValueError.\n",
    "        Возвращает:\n",
    "        koran: float-найденныйкорень\n",
    "        steps:list[dict]- данные окаждомшаге (a_k,b_k,mid,\n",
    "        f(mid)).\n",
    "        \"\"\"\n",
    "        fa = self.f(a)\n",
    "        fb = self.f(b)\n",
    "        if fa * fb > 0:\n",
    "            raise ValueError(\n",
    "                'Нетcмены знака наотрезке[a,b]: f(a)*f(b) >0=> корень негарантирован'\n",
    "            )\n",
    "\n",
    "        steps = []\n",
    "        for k in range(self.max_iter):\n",
    "            mid = 0.5 * (a + b)\n",
    "            fmid = self.f(mid)\n",
    "            steps.append({\n",
    "                'iter': k,\n",
    "                'a': a,\n",
    "                'b': b,\n",
    "                'mid': mid,\n",
    "                'f(mid)': fmid\n",
    "            })\n",
    "\n",
    "            if abs(b - a) < self.epsilon:\n",
    "                break\n",
    "\n",
    "            if fa * fmid <= 0:\n",
    "                #корень в[a,mid]\n",
    "                b = mid\n",
    "                fb = fmid\n",
    "            else:\n",
    "                #корень в[mid,b]\n",
    "                a = mid\n",
    "                fa = fmid\n",
    "\n",
    "        koran = 0.5 * (a + b)\n",
    "        return koran, steps\n",
    "\n",
    "    def find_all_korans(self, A, B, step=0.1):\n",
    "        \"\"\"\n",
    "        ИщетВСЕ корни f(x)=0на[A,B] через \"сканирование +бисекцию\":\n",
    "        1)Делим[A,B]на интервалы длиныstep.\n",
    "        2)Накаждом[x_i, x_{i+1}] проверяем f(x_i)*f(x_{i+1}) <=0.\n",
    "        3)Еслида, вызываем find_one_koran()=> получаем одинкорень.\n",
    "        4)Сливаемпочтиодинаковыекорни (расстояние <\n",
    "        self.merge_epsilon).\n",
    "        Возвращает:\n",
    "        korans:list[float]- список отсорт. уник.корней.\n",
    "        \"\"\"\n",
    "        # Создаем список точек с заданным шагом\n",
    "        x_points = []\n",
    "        current = A\n",
    "        while current <= B:\n",
    "            x_points.append(current)\n",
    "            current += step\n",
    "        \n",
    "        # Добавляем B, если он еще не добавлен\n",
    "        if x_points[-1] < B:\n",
    "            x_points.append(B)\n",
    "\n",
    "        found_korans = []\n",
    "        for i in range(len(x_points) - 1):\n",
    "            x_left = x_points[i]\n",
    "            x_right = x_points[i + 1]\n",
    "            f_left = self.f(x_left)\n",
    "            f_right = self.f(x_right)\n",
    "\n",
    "            if f_left * f_right > 0:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                koran, yoooo = self.find_one_koran(x_left, x_right)\n",
    "                found_korans.append(koran)\n",
    "            except ValueError:\n",
    "                #Корень ровно награнице\n",
    "                if abs(f_left) < self.epsilon:\n",
    "                    found_korans.append(x_left)\n",
    "                elif abs(f_right) < self.epsilon:\n",
    "                    found_korans.append(x_right)\n",
    "\n",
    "        #Слияние почти одинаковых корней\n",
    "        found_korans.sort()\n",
    "        merged_korans = []\n",
    "        for r in found_korans:\n",
    "            if not merged_korans:\n",
    "                merged_korans.append(r)\n",
    "            else:\n",
    "                if abs(r - merged_korans[-1]) < self.merge_epsilon:\n",
    "                    merged_korans[-1] = 0.5 * (merged_korans[-1] + r)\n",
    "                else:\n",
    "                    merged_korans.append(r)\n",
    "\n",
    "        return merged_korans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import copy\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "# Assume Bisect class is defined elsewhere and available globally for find_eigenvalues\n",
    "# Example:\n",
    "# class Bisect:\n",
    "#    def __init__(self, func, epsilon, max_iter, merge_epsilon): pass\n",
    "#    def find_all_korans(self, start, end, step): return [1.0, 2.0] # Placeholder\n",
    "\n",
    "class Matrix:\n",
    "    round_precision = 3\n",
    "    round_precision_eig = 2\n",
    "\n",
    "    def __init__(self, data):\n",
    "        if not isinstance(data, list) or not all(isinstance(row, list) for row in data):\n",
    "            raise TypeError(\"Input must be a list of lists\")\n",
    "        # Basic check for consistent row lengths, assumes non-empty matrix if applicable\n",
    "        if data and data[0]:\n",
    "             cols = len(data[0])\n",
    "             if not all(len(row) == cols for row in data):\n",
    "                 raise ValueError(\"All rows must have the same number of columns\")\n",
    "        self.data = data\n",
    "        self.rows = len(data)\n",
    "        self.cols = len(data[0]) if self.rows > 0 else 0\n",
    "\n",
    "    def dot(self, other): #like\n",
    "        if not isinstance(other, Matrix):\n",
    "             raise TypeError(\"Can only multiply by another Matrix object\")\n",
    "        if self.cols != other.rows:\n",
    "            raise ValueError(\"Matrix dimensions incompatible for multiplication\")\n",
    "\n",
    "        result_data = [[0 for _ in range(other.cols)] for _ in range(self.rows)]\n",
    "        for i in range(self.rows):\n",
    "            for j in range(other.cols):\n",
    "                sum_val = 0\n",
    "                for k in range(self.cols):\n",
    "                    sum_val += self.data[i][k] * other.data[k][j]\n",
    "                result_data[i][j] = sum_val\n",
    "        return Matrix(result_data)\n",
    "\n",
    "    def sumM(self, other): #like\n",
    "        if not isinstance(other, Matrix):\n",
    "            raise TypeError(\"Can only add another Matrix object\")\n",
    "        if self.rows != other.rows or self.cols != other.cols:\n",
    "            raise ValueError(\"Matrices must be the same size for addition\")\n",
    "\n",
    "        result_data = [[0 for _ in range(self.cols)] for _ in range(self.rows)]\n",
    "        for i in range(self.rows):\n",
    "            for j in range(self.cols):\n",
    "                result_data[i][j] = round(self.data[i][j] + other.data[i][j], self.round_precision)\n",
    "        return Matrix(result_data)\n",
    "\n",
    "    def tr(self): #лайк\n",
    "        result_data = [[self.data[j][i] for j in range(self.rows)] for i in range(self.cols)]\n",
    "        return Matrix(result_data)\n",
    "\n",
    "    def scalar(self, scalar_value):#like\n",
    "        if not isinstance(scalar_value, (int, float)):\n",
    "            raise TypeError(\"Scalar value must be a number\")\n",
    "        result_data = [[round(scalar_value * self.data[i][j], self.round_precision) for j in range(self.cols)] for i in range(self.rows)]\n",
    "        return Matrix(result_data)\n",
    "\n",
    "    def determinant(self):\n",
    "        if self.rows != self.cols:\n",
    "            raise ValueError(\"Matrix must be square to calculate determinant\")\n",
    "        n = self.rows\n",
    "        matrix_data = self.data\n",
    "\n",
    "        if n == 1:\n",
    "            return matrix_data[0][0]\n",
    "        if n == 2:\n",
    "            return matrix_data[0][0] * matrix_data[1][1] - matrix_data[0][1] * matrix_data[1][0]\n",
    "\n",
    "        det = 0\n",
    "        for j in range(n):\n",
    "            submatrix_data = [row[:j] + row[j+1:] for row in matrix_data[1:]]\n",
    "            submatrix = Matrix(submatrix_data)\n",
    "            sign = (-1) ** j\n",
    "            det += sign * matrix_data[0][j] * submatrix.determinant()\n",
    "        return det\n",
    "\n",
    "    def trace(self): #like\n",
    "        if self.rows != self.cols:\n",
    "            raise ValueError(\"Matrix must be square to calculate trace.\")\n",
    "        if self.rows == 0:\n",
    "            return 0\n",
    "        return sum(self.data[i][i] for i in range(self.rows))\n",
    "\n",
    "    \n",
    "    def identity(n): #like\n",
    "        data = [[1 if i == j else 0 for j in range(n)] for i in range(n)]\n",
    "        return Matrix(data)\n",
    "\n",
    "    def characteristic_polynomial(self): #like\n",
    "        if self.rows != self.cols:\n",
    "            raise ValueError(\"Matrix must be square.\")\n",
    "        n = self.rows\n",
    "        if n == 0:\n",
    "            raise ValueError(\"Matrix is empty.\")\n",
    "\n",
    "        I = Matrix.identity(n)\n",
    "        B = Matrix(copy.deepcopy(I.data))\n",
    "        coefficients = [1.0]\n",
    "        A_matrix = self\n",
    "\n",
    "        for k in range(1, n + 1):\n",
    "            M = A_matrix.dot(B)\n",
    "            tr_M = M.trace()\n",
    "            p_k = tr_M / k if k != 0 else 0\n",
    "            coefficients.append(-p_k)\n",
    "            scaled_I = I.scalar(p_k)\n",
    "            B = M.sumM(scaled_I.scalar(-1.0))\n",
    "\n",
    "        return coefficients\n",
    "\n",
    "    \n",
    "    def _polynomial_derivative(coeffs): #like\n",
    "        derivative = {}\n",
    "        for power, coeff in coeffs.items():\n",
    "            if power > 0:\n",
    "                derivative[power - 1] = power * coeff\n",
    "        return derivative\n",
    "\n",
    "    \n",
    "    def _create_polynomial_function(coeffs): #лайк\n",
    "        def poly_func(x):\n",
    "            return sum(coeff * (x ** power) for power, coeff in coeffs.items())\n",
    "        return poly_func\n",
    "\n",
    "    def find_eigenvalues(self, epsilon=1e-6, max_iter=1000, step=0.05,\n",
    "                         search_range=(-10000, 10000)): #лайк\n",
    "        if self.rows != self.cols:\n",
    "            raise ValueError(\"Matrix must be square.\")\n",
    "        n = self.rows\n",
    "        if n == 0: return [], []\n",
    "\n",
    "        coefs_list = self.characteristic_polynomial()\n",
    "        coefs_dict = dict(zip(range(len(coefs_list)-1, -1, -1), coefs_list))\n",
    "\n",
    "        f = Matrix._create_polynomial_function(coefs_dict)\n",
    "\n",
    "        derivatives = {}\n",
    "        current_coeffs = coefs_dict.copy()\n",
    "        for i in range(1, len(coefs_list)):\n",
    "            current_coeffs = Matrix._polynomial_derivative(current_coeffs)\n",
    "            if not current_coeffs: break\n",
    "            derivatives[i] = Matrix._create_polynomial_function(current_coeffs)\n",
    "\n",
    "        try:\n",
    "            # This external dependency needs to be provided in the environment\n",
    "            zist = Bisect(f, epsilon=epsilon, max_iter=max_iter, merge_epsilon=epsilon)\n",
    "            eigenvalues_raw = zist.find_all_korans(search_range[0], search_range[1], step)\n",
    "        except NameError:\n",
    "             print(\"Warning: Bisect class not found. Eigenvalue calculation requires Bisect.\")\n",
    "             return [], [] # Cannot proceed without Bisect\n",
    "\n",
    "        eigenvalues_rounded = [round(e, self.round_precision_eig) for e in eigenvalues_raw]\n",
    "\n",
    "        def get_algk(eigenvalue):\n",
    "            if abs(f(eigenvalue)) >= 1e-3: return 0\n",
    "            mult = 1\n",
    "            for i in range(1, len(coefs_list)):\n",
    "                if i in derivatives:\n",
    "                    deriv_func = derivatives[i]\n",
    "                    if abs(deriv_func(eigenvalue)) < 1e-3: mult += 1\n",
    "                    else: break\n",
    "                else: break\n",
    "            return mult\n",
    "\n",
    "        unique_eigenvalues = sorted(list(set(eigenvalues_rounded)))\n",
    "        algebraic_algks = [get_algk(ev) for ev in unique_eigenvalues]\n",
    "\n",
    "        final_eigenvalues = []\n",
    "        final_algks = []\n",
    "        total_multiplicity = 0\n",
    "        for ev, mult in zip(unique_eigenvalues, algebraic_algks):\n",
    "             if mult > 0:\n",
    "                 final_eigenvalues.append(ev)\n",
    "                 final_algks.append(mult)\n",
    "                 total_multiplicity += mult\n",
    "\n",
    "        # Check if total multiplicity matches matrix dimension\n",
    "        if total_multiplicity != n:\n",
    "            print(f\"Warning: Sum of algebraic multiplicities ({total_multiplicity}) does not match matrix dimension ({n}). Results may be incomplete or inaccurate.\")\n",
    "\n",
    "\n",
    "        print(\"Eigenvalues and their Algebraic Multiplicities:\")\n",
    "        if not final_eigenvalues:\n",
    "             print(\" No eigenvalues found.\")\n",
    "        for i, (ev, mult) in enumerate(zip(final_eigenvalues, final_algks), 1):\n",
    "            print(f'λ_{i} = {ev}, a(λ_{i}) = {mult}')\n",
    "\n",
    "        return final_eigenvalues, final_algks\n",
    "\n",
    "    \n",
    "    def find_eigenvalues_and_vectors(self, max_iter=10000, tol=1e-5):\n",
    "\n",
    "        if self.rows != self.cols:\n",
    "            raise ValueError(\"Matrix must be square\")\n",
    "    \n",
    "        A = Matrix(copy.deepcopy(self.data))\n",
    "        n = self.rows\n",
    "        eigenvectors = Matrix.identity(n)\n",
    "    \n",
    "        for _ in range(max_iter):\n",
    "            # QR-разложение\n",
    "            Q, R = Matrix.qr_decomposition(A)\n",
    "            # Обновление A и накопление собственных векторов\n",
    "            A = R.dot(Q)\n",
    "            eigenvectors = eigenvectors.dot(Q)\n",
    "        \n",
    "            # Проверка сходимости (диагональная форма)\n",
    "            off_diag_norm = 0.0\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if i != j:\n",
    "                        off_diag_norm += A.data[i][j]**2\n",
    "            if off_diag_norm < tol:\n",
    "                break\n",
    "    \n",
    "        # Извлечение собственных значений (диагональ A)\n",
    "        eigenvalues = [A.data[i][i] for i in range(n)]\n",
    "    \n",
    "        # Нормализация собственных векторов\n",
    "        normalized_vectors = []\n",
    "        for i in range(n):\n",
    "            vec = [eigenvectors.data[j][i] for j in range(n)]\n",
    "            norm = math.sqrt(sum(x**2 for x in vec))\n",
    "            if norm > tol:\n",
    "                normalized_vectors.append([x/norm for x in vec])\n",
    "            else:\n",
    "                normalized_vectors.append(vec)\n",
    "    \n",
    "        return eigenvalues, normalized_vectors\n",
    "\n",
    "    def qr_decomposition(self):\n",
    "        n = self.rows\n",
    "        Q = Matrix([[0.0]*n for _ in range(n)])\n",
    "        R = Matrix([[0.0]*n for _ in range(n)])\n",
    "    \n",
    "        for j in range(n):\n",
    "            # Вектор-столбец A\n",
    "            v = [self.data[i][j] for i in range(n)]\n",
    "        \n",
    "            # Ортогонализация относительно предыдущих столбцов\n",
    "            for i in range(j):\n",
    "                R.data[i][j] = sum(Q.data[k][i] * self.data[k][j] for k in range(n))\n",
    "                v = [v[k] - R.data[i][j] * Q.data[k][i] for k in range(n)]\n",
    "        \n",
    "            # Нормализация\n",
    "            norm = math.sqrt(sum(x**2 for x in v))\n",
    "            if norm < 1e-10:\n",
    "                raise ValueError(\"Matrix is rank deficient\")\n",
    "            \n",
    "            R.data[j][j] = norm\n",
    "            for i in range(n):\n",
    "                Q.data[i][j] = v[i] / norm\n",
    "    \n",
    "        return Q, R\n",
    "    \n",
    "    def solve(A_matrix, b_vector, max_solves=None): #like\n",
    "        if not isinstance(A_matrix, Matrix): raise TypeError(\"A must be a Matrix object\")\n",
    "        if not isinstance(b_vector, list): raise TypeError(\"b must be a list\")\n",
    "\n",
    "        A = copy.deepcopy(A_matrix.data)\n",
    "        b = copy.deepcopy(b_vector)\n",
    "        n = A_matrix.rows\n",
    "        m = A_matrix.cols\n",
    "\n",
    "        if n == 0: return []\n",
    "        if len(b) != n: raise ValueError(\"Matrix rows must match vector length\")\n",
    "        if m < n: print(\"Warning: Underdetermined system (more equations than variables)\") # Though typically m >= n\n",
    "\n",
    "        if max_solves is None: max_solves = m\n",
    "\n",
    "        augmented = [A[i] + [b[i]] for i in range(n)]\n",
    "        \n",
    "        current_rows = n\n",
    "        current_cols = m # Number of variables\n",
    "\n",
    "        # Gaussian elimination with partial pivoting\n",
    "        pivot_cols = []\n",
    "        rank = 0\n",
    "        pivot_row_map = list(range(n)) # Maps original row index to current position\n",
    "\n",
    "        for j in range(current_cols): # Iterate through variable columns\n",
    "             if rank >= current_rows: break # Stop if all rows processed\n",
    "\n",
    "             # Find pivot row below current rank\n",
    "             max_row_idx_local = rank\n",
    "             for i in range(rank + 1, current_rows):\n",
    "                  if abs(augmented[pivot_row_map[i]][j]) > abs(augmented[pivot_row_map[max_row_idx_local]][j]):\n",
    "                      max_row_idx_local = i\n",
    "\n",
    "             # Swap rows in the map\n",
    "             pivot_row_map[rank], pivot_row_map[max_row_idx_local] = pivot_row_map[max_row_idx_local], pivot_row_map[rank]\n",
    "             \n",
    "             pivot_row_original_idx = pivot_row_map[rank]\n",
    "\n",
    "             # Check if pivot is non-zero\n",
    "             if abs(augmented[pivot_row_original_idx][j]) < 1e-10:\n",
    "                  continue # Skip column if pivot is zero\n",
    "\n",
    "             pivot_val = augmented[pivot_row_original_idx][j]\n",
    "             pivot_cols.append(j) # Store pivot column index\n",
    "\n",
    "             # Eliminate elements below the pivot in the current column j\n",
    "             for i in range(rank + 1, current_rows):\n",
    "                  target_row_original_idx = pivot_row_map[i]\n",
    "                  factor = augmented[target_row_original_idx][j] / pivot_val\n",
    "                  # Apply row operation R_i = R_i - factor * R_pivot\n",
    "                  for k in range(j, current_cols + 1): # Include augmented column\n",
    "                      augmented[target_row_original_idx][k] -= factor * augmented[pivot_row_original_idx][k]\n",
    "                  # Zero out small numbers resulting from subtraction\n",
    "                  if abs(augmented[target_row_original_idx][j]) < 1e-12:\n",
    "                      augmented[target_row_original_idx][j] = 0.0\n",
    "             \n",
    "             rank += 1\n",
    "        \n",
    "        # Reorder rows physically based on final pivot_row_map for back-substitution\n",
    "        ordered_matrix_data = [augmented[pivot_row_map[i]] for i in range(current_rows)]\n",
    "\n",
    "        # Check for inconsistency\n",
    "        for i in range(rank, current_rows):\n",
    "             # Check rows that should be all zero in the coefficient part\n",
    "             if all(abs(ordered_matrix_data[i][k]) < 1e-10 for k in range(current_cols)):\n",
    "                  if abs(ordered_matrix_data[i][current_cols]) > 1e-10:\n",
    "                       return None # Inconsistent system: 0 = non-zero\n",
    "\n",
    "        # Back-substitution / Solution finding\n",
    "        solutions = []\n",
    "        free_variable_indices = [j for j in range(current_cols) if j not in pivot_cols]\n",
    "        \n",
    "        # Generate solutions\n",
    "        # We need to find a particular solution and optionally basis vectors for null space if infinite solutions\n",
    "        # The original recursive approach was complex; implementing a standard approach:\n",
    "        \n",
    "        if len(free_variable_indices) == 0: # Unique solution or possibly inconsistent (already checked)\n",
    "            if rank < current_cols:\n",
    "                 # This case (rank < cols but no free vars) implies dependent columns,\n",
    "                 # which should have resulted in free vars. Might indicate issue.\n",
    "                 # Or it could be an overdetermined system with a unique solution.\n",
    "                 print(\"Warning: System rank might be less than number of variables, but no free variables identified.\")\n",
    "                 # Proceed assuming a unique solution is determined by the rank rows\n",
    "\n",
    "            sol = [0.0] * current_cols\n",
    "            for i in range(rank - 1, -1, -1):\n",
    "                 pivot_col_idx = pivot_cols[i] # The column index for the pivot in this row\n",
    "                 pivot_val = ordered_matrix_data[i][pivot_col_idx]\n",
    "                 \n",
    "                 if abs(pivot_val) < 1e-10: continue # Should not happen with proper pivoting\n",
    "\n",
    "                 rhs = ordered_matrix_data[i][current_cols] # b value\n",
    "                 for j in range(pivot_col_idx + 1, current_cols):\n",
    "                      rhs -= ordered_matrix_data[i][j] * sol[j]\n",
    "                 \n",
    "                 sol[pivot_col_idx] = rhs / pivot_val\n",
    "            \n",
    "            solutions.append([round(val, Matrix.round_precision) for val in sol])\n",
    "\n",
    "        else: # Infinite solutions\n",
    "             # Find one particular solution (set free variables to 0)\n",
    "             particular_sol = [0.0] * current_cols\n",
    "             for i in range(rank - 1, -1, -1):\n",
    "                  pivot_col_idx = pivot_cols[i]\n",
    "                  pivot_val = ordered_matrix_data[i][pivot_col_idx]\n",
    "                  if abs(pivot_val) < 1e-10: continue\n",
    "\n",
    "                  rhs = ordered_matrix_data[i][current_cols]\n",
    "                  for j in range(pivot_col_idx + 1, current_cols):\n",
    "                       # Only subtract terms involving basic variables (already computed)\n",
    "                       # or free variables (which are 0 for particular solution)\n",
    "                       if j not in free_variable_indices:\n",
    "                            rhs -= ordered_matrix_data[i][j] * particular_sol[j]\n",
    "                       # else: term is ordered_matrix[i][j] * 0 = 0\n",
    "                  \n",
    "                  particular_sol[pivot_col_idx] = rhs / pivot_val\n",
    "             \n",
    "             # For finding multiple solutions as requested by max_solves:\n",
    "             # We can generate them by assigning simple values (like 0, 1) to free variables.\n",
    "             # Generate combinations of free variable assignments.\n",
    "             num_free = len(free_variable_indices)\n",
    "             if max_solves > 2**num_free: max_solves = 2**num_free # Limit to possible combinations\n",
    "             \n",
    "             count = 0\n",
    "             # Iterate through assignments like (0,0,..), (1,0,..), (0,1,..), (1,1,..) etc.\n",
    "             # Using binary representation of numbers 0 to max_solves-1 (or 2**num_free - 1)\n",
    "             \n",
    "             # Ensure max_solves is reasonable\n",
    "             max_attempts = min(max_solves, 2**num_free if num_free < 10 else 1024) # Limit attempts for many free vars\n",
    "\n",
    "             for i_assign in range(max_attempts):\n",
    "                  if len(solutions) >= max_solves: break\n",
    "                  \n",
    "                  current_sol = [0.0] * current_cols\n",
    "                  temp_assign = i_assign\n",
    "                  \n",
    "                  # Set free variable values for this iteration\n",
    "                  free_var_values = {}\n",
    "                  for k in range(num_free):\n",
    "                      free_idx = free_variable_indices[k]\n",
    "                      val = float(temp_assign % 2) # Assign 0 or 1\n",
    "                      current_sol[free_idx] = val\n",
    "                      free_var_values[free_idx] = val\n",
    "                      temp_assign //= 2\n",
    "\n",
    "                  # Calculate basic variable values based on these free var assignments\n",
    "                  for i_row in range(rank - 1, -1, -1):\n",
    "                       pivot_col_idx = pivot_cols[i_row]\n",
    "                       pivot_val = ordered_matrix_data[i_row][pivot_col_idx]\n",
    "                       if abs(pivot_val) < 1e-10: continue\n",
    "\n",
    "                       rhs = ordered_matrix_data[i_row][current_cols]\n",
    "                       for j_col in range(pivot_col_idx + 1, current_cols):\n",
    "                            rhs -= ordered_matrix_data[i_row][j_col] * current_sol[j_col] # Uses already set basic or free vars\n",
    "\n",
    "                       current_sol[pivot_col_idx] = rhs / pivot_val\n",
    "                       \n",
    "                  solutions.append([round(val, Matrix.round_precision) for val in current_sol])\n",
    "\n",
    "        # Remove duplicates just in case generation method created them\n",
    "        unique_solutions = []\n",
    "        seen_solutions = set()\n",
    "        for sol in solutions:\n",
    "            sol_tuple = tuple(sol)\n",
    "            if sol_tuple not in seen_solutions:\n",
    "                unique_solutions.append(sol)\n",
    "                seen_solutions.add(sol_tuple)\n",
    "                \n",
    "        return unique_solutions if unique_solutions else None\n",
    "\n",
    "\n",
    "    \n",
    "    def _remove_lz(vectors_list): #like\n",
    "        if not vectors_list: return []\n",
    "\n",
    "        matrix_data = [list(vec) for vec in vectors_list]\n",
    "        original_indices = list(range(len(matrix_data)))\n",
    "\n",
    "        rows = len(matrix_data)\n",
    "        cols = len(matrix_data[0]) if rows > 0 else 0\n",
    "\n",
    "        rank = 0\n",
    "        pivot_row_indices = []\n",
    "\n",
    "        for col in range(cols):\n",
    "            if rank >= rows: break\n",
    "\n",
    "            max_row_idx = rank\n",
    "            for current_row_idx in range(rank + 1, rows):\n",
    "                if abs(matrix_data[max_row_idx][col]) < abs(matrix_data[current_row_idx][col]):\n",
    "                     max_row_idx = current_row_idx\n",
    "\n",
    "            if abs(matrix_data[max_row_idx][col]) > 1e-10:\n",
    "                matrix_data[rank], matrix_data[max_row_idx] = matrix_data[max_row_idx], matrix_data[rank]\n",
    "                original_indices[rank], original_indices[max_row_idx] = original_indices[max_row_idx], original_indices[rank]\n",
    "\n",
    "                pivot_value = matrix_data[rank][col]\n",
    "                for i in range(rank + 1, rows):\n",
    "                    factor = matrix_data[i][col] / pivot_value\n",
    "                    for j in range(col, cols):\n",
    "                        matrix_data[i][j] -= factor * matrix_data[rank][j]\n",
    "                    if abs(matrix_data[i][col]) < 1e-10:\n",
    "                        matrix_data[i][col] = 0.0\n",
    "\n",
    "                pivot_row_indices.append(original_indices[rank])\n",
    "                rank += 1\n",
    "\n",
    "        return [vectors_list[i] for i in pivot_row_indices]\n",
    "\n",
    "    def find_eigenvectors(self): #like\n",
    "        if self.rows != self.cols: raise ValueError(\"Matrix must be square.\")\n",
    "        n = self.rows\n",
    "        if n == 0: return [], []\n",
    "\n",
    "        eigenvalues_result = self.find_eigenvalues()\n",
    "        if not eigenvalues_result or not eigenvalues_result[0]:\n",
    "             print(\"Could not find eigenvalues or no eigenvalues found.\")\n",
    "             return [], []\n",
    "\n",
    "        eigenvalues, algebraic_multiplicities = eigenvalues_result\n",
    "        all_eigenvectors = []\n",
    "        geometric_multiplicities = []\n",
    "        eigenpairs = [] # Store {'value': v, 'vectors': [list]}\n",
    "\n",
    "        I = Matrix.identity(n)\n",
    "\n",
    "        for eigenvalue, alg_mult in zip(eigenvalues, algebraic_multiplicities):\n",
    "            lambda_I = I.scalar(eigenvalue)\n",
    "            A_minus_lambda_I = self.sumM(lambda_I.scalar(-1.0))\n",
    "            b_zero = [0.0] * n\n",
    "\n",
    "            null_space_vectors = Matrix.solve(A_minus_lambda_I, b_zero, max_solves=n) # Request enough potential basis vectors\n",
    "\n",
    "            if null_space_vectors is None:\n",
    "                eigenvectors_for_lambda = []\n",
    "            else:\n",
    "                eigenvectors_for_lambda = [vec for vec in null_space_vectors if any(abs(x) > 1e-9 for x in vec)]\n",
    "\n",
    "            independent_eigenvectors = Matrix._remove_lz(eigenvectors_for_lambda)\n",
    "            \n",
    "            # Normalize eigenvectors\n",
    "            normalized_eigenvectors = []\n",
    "            for vec in independent_eigenvectors:\n",
    "                 norm = sum(x**2 for x in vec)**0.5\n",
    "                 if norm > 1e-9:\n",
    "                     normalized_eigenvectors.append([x / norm for x in vec])\n",
    "                 else: # Keep zero vector if somehow generated (shouldn't be l.i.)\n",
    "                      normalized_eigenvectors.append(vec)\n",
    "\n",
    "            current_geom_mult = len(normalized_eigenvectors)\n",
    "            geometric_multiplicities.append(current_geom_mult)\n",
    "            all_eigenvectors.extend(normalized_eigenvectors)\n",
    "            eigenpairs.append({'value': eigenvalue, 'vectors': normalized_eigenvectors, 'alg_mult': alg_mult, 'geom_mult': current_geom_mult})\n",
    "\n",
    "            if current_geom_mult < alg_mult:\n",
    "                 print(f\"Warning: Geometric multiplicity ({current_geom_mult}) is less than algebraic multiplicity ({alg_mult}) for λ = {eigenvalue}. Matrix may not be diagonalizable.\")\n",
    "            elif current_geom_mult > alg_mult:\n",
    "                 # This indicates a potential issue in calculation (g(λ) <= a(λ) always)\n",
    "                 print(f\"Warning: Calculated geometric multiplicity ({current_geom_mult}) > algebraic multiplicity ({alg_mult}) for λ = {eigenvalue}. Check calculations.\")\n",
    "\n",
    "\n",
    "        print(\"\\nGeometric Multiplicities:\")\n",
    "        if not eigenpairs:\n",
    "             print(\" No eigenvectors found.\")\n",
    "        for i, pair in enumerate(eigenpairs, 1):\n",
    "             print(f'g(λ_{i}) = {pair[\"geom_mult\"]} for λ_{i} = {pair[\"value\"]}')\n",
    "\n",
    "        # Return list of all basis eigenvectors found, and list of geometric multiplicities corresponding to the order of eigenvalues from find_eigenvalues\n",
    "        return all_eigenvectors, geometric_multiplicities\n",
    "\n",
    "    \n",
    "    \n",
    "    def center_data(matrix_obj): #like\n",
    "        if not isinstance(matrix_obj, Matrix): raise TypeError(\"Input must be a Matrix object\")\n",
    "        X_data = matrix_obj.data\n",
    "        num_samples = matrix_obj.rows\n",
    "        num_features = matrix_obj.cols\n",
    "        if num_samples == 0: return Matrix([]), [0.0] * num_features\n",
    "\n",
    "        means = [0.0] * num_features\n",
    "        for j in range(num_features):\n",
    "            col_sum = sum(X_data[i][j] for i in range(num_samples))\n",
    "            means[j] = col_sum / num_samples\n",
    "\n",
    "        centered_data = [[X_data[i][j] - means[j] for j in range(num_features)] for i in range(num_samples)]\n",
    "        return Matrix(centered_data), means\n",
    "\n",
    "    \n",
    "    def covariance_matrix(matrix_obj): #like mb not like\n",
    "         if not isinstance(matrix_obj, Matrix): raise TypeError(\"Input must be a Matrix object\")\n",
    "         X_centered = matrix_obj\n",
    "         n_samples = X_centered.rows\n",
    "         if n_samples <= 1:\n",
    "              print(\"Warning: Covariance matrix is undefined or zero for <= 1 sample.\")\n",
    "              return Matrix([[0.0] * X_centered.cols for _ in range(X_centered.cols)])\n",
    "\n",
    "         X_T = X_centered.tr()\n",
    "         XTX = X_T.dot(X_centered)\n",
    "         cov_matrix = XTX.scalar(1.0 / (n_samples - 1))\n",
    "         return cov_matrix\n",
    "\n",
    "    \n",
    "    def explained_variance_ratio(eigenpairs, n_components): #like\n",
    "        return sum(eig for eig, _ in eigenpairs[:n_components]) / sum(eig for eig, _ in eigenpairs)\n",
    "\n",
    "    def auto_select_k(eigenvalues, threshold: float = 0.95):\n",
    "        \n",
    "        sorted_eigenvalues = sorted(eigenvalues, reverse=True)\n",
    "        total_variance = sum(sorted_eigenvalues)\n",
    "        cumulative_variance = 0.0\n",
    "    \n",
    "        for k, eigval in enumerate(sorted_eigenvalues, 1):\n",
    "            cumulative_variance += eigval / total_variance\n",
    "            if cumulative_variance >= threshold:\n",
    "                return k\n",
    "    \n",
    "        return len(sorted_eigenvalues)\n",
    "\n",
    "    \n",
    "    def PCA(input_matrix, n_components=None, threshold=0.95):\n",
    "\n",
    "        # Проверка входных данных\n",
    "        if not isinstance(input_matrix, Matrix):\n",
    "            raise TypeError(\"Input must be a Matrix object\")\n",
    "        if input_matrix.rows == 0 or input_matrix.cols == 0:\n",
    "            return Matrix([]), Matrix([]), [], 0.0\n",
    "    \n",
    "        # 1. Центрирование данных\n",
    "        X_centered, means = Matrix.center_data(input_matrix)\n",
    "    \n",
    "        # 2. Вычисление ковариационной матрицы\n",
    "        cov_mat = Matrix.covariance_matrix(X_centered)\n",
    "    \n",
    "        # 3. Нахождение собственных значений и векторов (улучшенный метод)\n",
    "        try:\n",
    "            eigenvalues, eigenvectors = cov_mat.find_eigenvalues_and_vectors()\n",
    "            if not eigenvalues or not eigenvectors:\n",
    "                raise ValueError(\"No eigenvalues/vectors found\")\n",
    "        except Exception as e:\n",
    "            print(f\"PCA failed in eigenvalue decomposition: {str(e)}\")\n",
    "            return Matrix([]), Matrix([]), means, 0.0\n",
    "    \n",
    "        # 4. Сортировка по убыванию собственных значений\n",
    "        eigenpairs = sorted(zip(eigenvalues, eigenvectors), \n",
    "                       key=lambda x: -x[0])\n",
    "    \n",
    "        # 5. Автоматический выбор числа компонент\n",
    "        if n_components is None:\n",
    "            n_components = Matrix.auto_select_k(eigenvalues, threshold)\n",
    "        else:\n",
    "            n_components = min(n_components, len(eigenvectors))\n",
    "    \n",
    "        # 6. Выбор главных компонент\n",
    "        components = [vec for eig, vec in eigenpairs[:n_components]]\n",
    "        if not components:\n",
    "            print(\"Warning: No principal components selected\")\n",
    "            return Matrix([]), Matrix([]), means, 0.0\n",
    "    \n",
    "        # 7. Формирование матрицы проекции\n",
    "        W = Matrix(components)  # Транспонируем для правильной размерности\n",
    "    \n",
    "        # 8. Проекция данных\n",
    "        X_proj = X_centered.dot(W)\n",
    "    \n",
    "        # 9. Вычисление объясненной дисперсии\n",
    "        explained_variance = Matrix.explained_variance_ratio(eigenpairs, n_components)\n",
    "    \n",
    "        return X_proj, W, means, explained_variance\n",
    "    \n",
    "    \n",
    "    def inverse_PCA(X_proj, components, means):\n",
    "         if not isinstance(X_proj, Matrix) or not isinstance(components, Matrix):\n",
    "             raise TypeError(\"Inputs X_proj and components must be Matrix objects\")\n",
    "\n",
    "         W = components # (k x d), eigenvectors as rows\n",
    "         if X_proj.cols != W.rows:\n",
    "              raise ValueError(f\"Projected data columns ({X_proj.cols}) must match number of components ({W.rows})\")\n",
    "         if W.cols != len(means):\n",
    "              raise ValueError(f\"Component feature dimension ({W.cols}) must match number of means ({len(means)})\")\n",
    "\n",
    "\n",
    "         X_rec_centered = X_proj.dot(W.tr()) # (n x k) dot (k x d) -> (n x d)\n",
    "\n",
    "         reconstructed_data = [[X_rec_centered.data[i][j] + means[j] for j in range(len(means))]\n",
    "                               for i in range(X_rec_centered.rows)]\n",
    "\n",
    "         return Matrix(reconstructed_data)\n",
    "    \n",
    "    \n",
    "    def reconstruction_error(X_orig, X_recon):\n",
    "        if X_orig.rows != X_recon.rows or X_orig.cols != X_recon.cols:\n",
    "            raise ValueError(\"Размерности исходной и восстановленной матриц должны совпадать\")\n",
    "    \n",
    "        total_squared_error = 0.0\n",
    "        for i in range(X_orig.rows):\n",
    "            for j in range(X_orig.cols):\n",
    "                error = X_orig.data[i][j] - X_recon.data[i][j]\n",
    "                total_squared_error += error ** 2\n",
    "    \n",
    "        mse = total_squared_error / (X_orig.rows * X_orig.cols)\n",
    "        return mse\n",
    "    \n",
    "    def plot_pca_projection(X_pca):\n",
    "        if X_pca.cols != 2:\n",
    "            raise ValueError(\"Projection matrix must have 2 columns\")\n",
    "    \n",
    "        x = [row[0] for row in X_pca.data]\n",
    "        y = [row[1] for row in X_pca.data]\n",
    "    \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(x, y)\n",
    "        ax.set_xlabel('First Principal Component')\n",
    "        ax.set_ylabel('Second Principal Component')\n",
    "        ax.set_title('PCA Projection')\n",
    "    \n",
    "        return fig\n",
    "    \n",
    "    def handle_missing_values(X):\n",
    "        filled_data = [row.copy() for row in X.data]\n",
    "        n_rows, n_cols = X.rows, X.cols\n",
    "    \n",
    "        for j in range(n_cols):\n",
    "            # Собираем все не-NaN значения в столбце\n",
    "            column_values = []\n",
    "            for i in range(n_rows):\n",
    "                val = filled_data[i][j]\n",
    "                if val is not None and not (isinstance(val, float) and math.isnan(val)):\n",
    "                    column_values.append(val)\n",
    "        \n",
    "            if not column_values:\n",
    "                column_mean = 0.0  # если все значения NaN, заменяем на 0\n",
    "            else:\n",
    "                column_mean = sum(column_values) / len(column_values)\n",
    "        \n",
    "            # Заменяем NaN на среднее\n",
    "            for i in range(n_rows):\n",
    "                val = filled_data[i][j]\n",
    "                if val is None or (isinstance(val, float) and math.isnan(val)):\n",
    "                    filled_data[i][j] = column_mean\n",
    "    \n",
    "        return Matrix(filled_data)\n",
    "    def apply_pca_to_dataset(dataset_name, k: int = None, threshold: float = 0.95):\n",
    "        # Загрузка данных (пример для встроенных датасетов)\n",
    "        if dataset_name == 'iris':\n",
    "            from sklearn.datasets import load_iris\n",
    "            data = load_iris()\n",
    "            X = Matrix(data['data'].tolist())\n",
    "            y = data['target']\n",
    "        elif dataset_name == 'wine':\n",
    "            from sklearn.datasets import load_wine\n",
    "            data = load_wine()\n",
    "            X = Matrix(data['data'].tolist())\n",
    "            y = data['target']\n",
    "        else:\n",
    "            # Для CSV (предполагается, что последний столбец — целевая переменная)\n",
    "            import csv\n",
    "            with open(dataset_name, 'r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                data = [list(map(float, row)) for row in reader]\n",
    "            X = Matrix([row[:-1] for row in data])\n",
    "            y = [row[-1] for row in data]\n",
    "    \n",
    "        # Выполнение PCA\n",
    "        X_proj, components, means, ratio = Matrix.PCA(X, k)\n",
    "    \n",
    "        # Восстановление данных для оценки ошибки\n",
    "        X_recon = Matrix.inverse_PCA(X_proj, components, means)\n",
    "        mse = Matrix.reconstruction_error(X, X_recon)\n",
    "        return {\n",
    "            'X_proj': X_proj,\n",
    "            'explained_variance': ratio,\n",
    "            'mse': mse\n",
    "        }\n",
    "\n",
    "    def add_noise_and_compare(X, noise_level: float = 0.1):\n",
    "        # 1. Центрируем данные и вычисляем стандартные отклонения\n",
    "        X_centered, means = Matrix.center_data(X)\n",
    "        std_devs = [math.sqrt(sum(X_centered.data[i][j]**2 for i in range(X.rows)) / (X.rows - 1)) for j in range(X.cols)]\n",
    "    \n",
    "    \n",
    "        # 2. Генерируем зашумленные данные\n",
    "        noisy_data = [\n",
    "            [\n",
    "                X.data[i][j] + random.gauss(0, std_devs[j] * noise_level)\n",
    "                for j in range(X.cols)\n",
    "            ]\n",
    "            for i in range(X.rows)\n",
    "        ]\n",
    "        X_noisy = Matrix(noisy_data)\n",
    "    \n",
    "        # 3. Выполняем PCA для исходных данных\n",
    "        X_proj_orig, components_orig, means_orig, ratio_orig = Matrix.PCA(X, n_components=X.cols)\n",
    "        X_recon_orig = Matrix.inverse_PCA(X_proj_orig, components_orig, means)\n",
    "        mse_orig = Matrix.reconstruction_error(X, X_recon_orig)\n",
    "    \n",
    "        # 4. Выполняем PCA для зашумленных данных\n",
    "        X_proj_noisy, components_noisy, means_noisy, ratio_noisy = Matrix.PCA(X_noisy, n_components=X.cols)\n",
    "    \n",
    "        # 5. Сравнение собственных значений\n",
    "        cov_orig = Matrix.covariance_matrix(X_centered)\n",
    "        eigenvalues_orig, eigenvaluesvectors_orig = cov_orig.find_eigenvalues_and_vectors()\n",
    "    \n",
    "        X_noisy_centered, means_noisy = Matrix.center_data(X_noisy)\n",
    "        cov_noisy = Matrix.covariance_matrix(X_noisy_centered)\n",
    "        eigenvalues_noisy, eigenvaluesvectors_noisy = cov_noisy.find_eigenvalues_and_vectors()\n",
    "    \n",
    "        return {\n",
    "            'eigenvalues_orig': eigenvalues_orig,\n",
    "            'eigenvalues_noisy': eigenvalues_noisy,\n",
    "            'explained_var_orig': ratio_orig,\n",
    "            'explained_var_noisy': ratio_noisy,\n",
    "            'mse_reconstruction': mse_orig\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_data = [\n",
    "[1, -2, 0, 0],\n",
    "[4, 7, 0, 0],\n",
    "[-6, -5, 1, -1],\n",
    "[8, 6, 4, 5]\n",
    "]\n",
    "\n",
    "def I(n):\n",
    "    m_ = []\n",
    "    for i in range(n):\n",
    "        m_.append([0 for j in range(n)])\n",
    "        m_[-1][i] = 1\n",
    "    return m_\n",
    "\n",
    "M = Matrix(M_data)\n",
    "X_centered, _ = Matrix.center_data(M)\n",
    "cov_mat = Matrix.covariance_matrix(X_centered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix M:\n",
      "[1, -2, 0, 0]\n",
      "[4, 7, 0, 0]\n",
      "[-6, -5, 1, -1]\n",
      "[8, 6, 4, 5]\n",
      "\n",
      "PCA Projected Data (X_pca):\n",
      "[0.90569, -2.98159, 0.39137, 2.3477]\n",
      "[0.80346, 4.05714, -3.91581, -2.33141]\n",
      "[-4.05812, -8.80564, 1.03501, 3.36098]\n",
      "[2.34896, 7.73008, 2.48943, -3.37727]\n",
      "\n",
      "Principal Components (Eigenvectors as rows):\n",
      "[0.68719, 0.67238, 0.114, 0.25036]\n",
      "[-0.24042, 0.55795, -0.51657, -0.60335]\n",
      "[-0.64639, 0.48042, 0.54357, 0.23645]\n",
      "[0.22837, -0.07606, 0.65168, -0.71929]\n",
      "\n",
      "Means:\n",
      "[1.75, 1.5, 1.25, 1.0]\n",
      "\n",
      "Reconstructed Matrix:\n",
      "[1.0, -2.0, -0.0, 0.0]\n",
      "[4.0, 7.0, -0.0, -0.0]\n",
      "[-6.0, -5.0, 1.0, -1.0]\n",
      "[8.0, 6.0, 4.0, 5.0]\n",
      "1 ошибка и ты ошибся 3.386623192149685e-22\n",
      "{'eigenvalues_orig': [71.10261199719706, 7.568870657087935, 2.1620684711764144, -0.0005511254614031583], 'eigenvalues_noisy': [67.40150331637976, 10.036306253370496, 2.4720787259382355, 0.00011170431152687926], 'explained_var_orig': 1.0, 'explained_var_noisy': 1.0, 'mse_reconstruction': 3.386623192149685e-22}\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Matrix M:\")\n",
    "for row in M.data: print(row)\n",
    "\n",
    "try:\n",
    "    # Perform PCA\n",
    "    # n_components can be set, e.g., n_components=2\n",
    "    n = 4\n",
    "    X_pca, components, means, ratio = Matrix.PCA(M, n_components=n)\n",
    "    if n == 2:\n",
    "        Matrix.plot_pca_projection(X_pca)\n",
    "    print(\"\\nPCA Projected Data (X_pca):\")\n",
    "    if X_pca.data:\n",
    "            for row in X_pca.data: print([round(x, 5) for x in row])\n",
    "    else: print(\" Empty\")\n",
    "\n",
    "    print(\"\\nPrincipal Components (Eigenvectors as rows):\")\n",
    "    if components.data:\n",
    "            for row in components.data: print([round(x, 5) for x in row])\n",
    "    else: print(\" Empty\")\n",
    "\n",
    "    print(\"\\nMeans:\")\n",
    "    print([round(x, 5) for x in means])\n",
    "\n",
    "    # Reconstruct data\n",
    "    M_reconstructed = Matrix.inverse_PCA(X_pca, components, means)\n",
    "\n",
    "    print(\"\\nReconstructed Matrix:\")\n",
    "    if M_reconstructed.data:\n",
    "            for row in M_reconstructed.data: print([round(x, 5) for x in row])\n",
    "    else: print(\" Empty\")\n",
    "    print(\"1 ошибка и ты ошибся\", Matrix.reconstruction_error(M, M_reconstructed))\n",
    "    \n",
    "    a = Matrix.add_noise_and_compare(M)\n",
    "    print(a)\n",
    "    print(ratio)\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"\\nAn error occurred during PCA processing: {e}\")\n",
    "    print(traceback.format_exc())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
